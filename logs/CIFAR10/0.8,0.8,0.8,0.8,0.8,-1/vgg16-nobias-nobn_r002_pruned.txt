Default training path used
Default testing path used
Loading from: ../checkpoints/CIFAR10/0.8,0.8,0.8,0.8,0.8,-1/vgg16-nobias-nobn_r002.pt
Dataset: CIFAR10
#######################################################################
Finished Loading Checkpoint
Epoch is:  17
Accuracy is:  79.10000000000001
Errors are:  20.89999999999999
Previous Masks keys:  dict_keys([1, 3, 6, 8, 11, 13, 15, 18, 20, 22, 25, 27, 29, 33, 36])
All task Masks keys:  dict_keys([0])
Conns keys:  dict_keys([0])
Conn_aves keys:  dict_keys([0])
Dataset2idx is:  {'CIFAR10': 1}
#######################################################################
current index is: 1
Manager created
Pruning
Prune percent is:  0.8
Freeze percent is:  0.02
Number of layers to freeze:  4
Freezing order:  random
Pre-prune eval:
Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  79.10000000000001
Pruning for dataset idx: 1
Pruning each layer by removing 80.00% of values
Layer #1, pruned 1348/1728 (78.01%) (Total in layer: 1728)
Layer #3, pruned 29491/36864 (80.00%) (Total in layer: 36864)
Layer #6, pruned 57508/73728 (78.00%) (Total in layer: 73728)
Layer #8, pruned 117965/147456 (80.00%) (Total in layer: 147456)
Layer #11, pruned 230031/294912 (78.00%) (Total in layer: 294912)
Layer #13, pruned 471859/589824 (80.00%) (Total in layer: 589824)
Layer #15, pruned 471859/589824 (80.00%) (Total in layer: 589824)
Layer #18, pruned 943718/1179648 (80.00%) (Total in layer: 1179648)
Layer #20, pruned 1887437/2359296 (80.00%) (Total in layer: 2359296)
Layer #22, pruned 1887437/2359296 (80.00%) (Total in layer: 2359296)
Layer #25, pruned 1887437/2359296 (80.00%) (Total in layer: 2359296)
Layer #27, pruned 1840251/2359296 (78.00%) (Total in layer: 2359296)
Layer #29, pruned 1887437/2359296 (80.00%) (Total in layer: 2359296)
Layer #33, pruned 204472/262144 (78.00%) (Total in layer: 262144)
Layer #36, pruned 209715/262144 (80.00%) (Total in layer: 262144)

FOR TASK %d: 1
Layer #1: Frozen 380/1728 (21.99%)
Layer #3: Frozen 7373/36864 (20.00%)
Layer #6: Frozen 16220/73728 (22.00%)
Layer #8: Frozen 29491/147456 (20.00%)
Layer #11: Frozen 64881/294912 (22.00%)
Layer #13: Frozen 117965/589824 (20.00%)
Layer #15: Frozen 117965/589824 (20.00%)
Layer #18: Frozen 235930/1179648 (20.00%)
Layer #20: Frozen 471859/2359296 (20.00%)
Layer #22: Frozen 471859/2359296 (20.00%)
Layer #25: Frozen 471859/2359296 (20.00%)
Layer #27: Frozen 519045/2359296 (22.00%)
Layer #29: Frozen 471859/2359296 (20.00%)
Layer #33: Frozen 57672/262144 (22.00%)
Layer #36: Frozen 52429/262144 (20.00%)
Checking...
Layer #1: Pruned 1348/1728 (78.01%)
Layer #3: Pruned 29491/36864 (80.00%)
Layer #6: Pruned 57508/73728 (78.00%)
Layer #8: Pruned 117965/147456 (80.00%)
Layer #11: Pruned 230031/294912 (78.00%)
Layer #13: Pruned 471859/589824 (80.00%)
Layer #15: Pruned 471859/589824 (80.00%)
Layer #18: Pruned 943718/1179648 (80.00%)
Layer #20: Pruned 1887437/2359296 (80.00%)
Layer #22: Pruned 1887437/2359296 (80.00%)
Layer #25: Pruned 1887437/2359296 (80.00%)
Layer #27: Pruned 1840251/2359296 (78.00%)
Layer #29: Pruned 1887437/2359296 (80.00%)
Layer #33: Pruned 204472/262144 (78.00%)
Layer #36: Pruned 209715/262144 (80.00%)

Post-prune eval:
Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  15.89
Doing some extra finetuning...
Epoch:  0
Accuracy of the network on the 10000 test images: 69.270000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  69.27
Best model so far, Accuracy: 15.89% -> 69.27%
Epoch:  1
Accuracy of the network on the 10000 test images: 74.560000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  74.56
Best model so far, Accuracy: 69.27% -> 74.56%
Epoch:  2
Accuracy of the network on the 10000 test images: 76.330000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  76.33
Best model so far, Accuracy: 74.56% -> 76.33%
Epoch:  3
Accuracy of the network on the 10000 test images: 77.120000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  77.12
Best model so far, Accuracy: 76.33% -> 77.12%
Epoch:  4
Accuracy of the network on the 10000 test images: 77.870000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  77.86999999999999
Best model so far, Accuracy: 77.12% -> 77.87%
Epoch:  5
Accuracy of the network on the 10000 test images: 77.980000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  77.98
Best model so far, Accuracy: 77.87% -> 77.98%
Epoch:  6
Accuracy of the network on the 10000 test images: 78.320000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  78.32000000000001
Best model so far, Accuracy: 77.98% -> 78.32%
Epoch:  7
Accuracy of the network on the 10000 test images: 78.380000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  78.38000000000001
Best model so far, Accuracy: 78.32% -> 78.38%
Epoch:  8
Accuracy of the network on the 10000 test images: 78.520000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  78.52
Best model so far, Accuracy: 78.38% -> 78.52%
Epoch:  9
Accuracy of the network on the 10000 test images: 78.480000 %

Current idx: 1
Applying dataset mask for dataset:  1
Performing eval...
Accuracy is:  78.48
Finished finetuning...
Best error/accuracy: 21.48%, 78.52%
----------------
----------------
Pruning summary:
Checking...
Layer #1: Pruned 1348/1728 (78.01%)
Layer #3: Pruned 29491/36864 (80.00%)
Layer #6: Pruned 57508/73728 (78.00%)
Layer #8: Pruned 117965/147456 (80.00%)
Layer #11: Pruned 230031/294912 (78.00%)
Layer #13: Pruned 471859/589824 (80.00%)
Layer #15: Pruned 471859/589824 (80.00%)
Layer #18: Pruned 943718/1179648 (80.00%)
Layer #20: Pruned 1887437/2359296 (80.00%)
Layer #22: Pruned 1887437/2359296 (80.00%)
Layer #25: Pruned 1887437/2359296 (80.00%)
Layer #27: Pruned 1840251/2359296 (78.00%)
Layer #29: Pruned 1887437/2359296 (80.00%)
Layer #33: Pruned 204472/262144 (78.00%)
Layer #36: Pruned 209715/262144 (80.00%)
----------------








